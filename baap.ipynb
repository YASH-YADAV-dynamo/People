{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b2c35c-3bc0-46d9-b816-6c19ae3959df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 08:38:20.136991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 08:38:27.559021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# !pip install cvlib\n",
    "import cvlib\n",
    "import cvlib as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d823264-e205-48ef-8a70-d0d6b1a8030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "from vidgear.gears import CamGear    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9bc3c1-aee3-4305-8d1b-e7013f586337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m08:31:54\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37mRunning VidGear Version: 0.3.2\u001b[0m\n",
      "\u001b[32m08:31:54\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;31m\u001b[2;33mWARNING \u001b[0m :: \u001b[1;37mGStreamer not found!\u001b[0m\n",
      "\u001b[32m08:31:54\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mSelecting `best` resolution for streams.\u001b[0m\n",
      "\u001b[32m08:31:54\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37mVerifying Streaming URL using yt-dlp backend. Please wait...\u001b[0m\n",
      "\u001b[32m08:31:58\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37m[Backend] :: Streaming URL is fully supported. Available Streams are: [144p, 240p, 360p, 480p, 720p, 1080p, best, worst]\u001b[0m\n",
      "\u001b[32m08:31:58\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;31m\u001b[2;33mWARNING \u001b[0m :: \u001b[1;37mLivestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\u001b[0m\n",
      "\u001b[32m08:31:58\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mUsing `best` resolution for streaming.\u001b[0m\n",
      "\u001b[32m08:31:58\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mYouTube source ID: `DjdUEyjx8GM`, Title: `【 LIVE 】東京都 新宿 歌舞伎町 24時間 ライブ / Tokyo Shinjuku Kabukicho Live 2024-04-09 08:31`, Quality: `best`\u001b[0m\n",
      "\u001b[32m08:31:58\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mEnabling Threaded Queue Mode for the current video source!\u001b[0m\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "[tls @ 0x55b3bfab7f00] IO error: End of file\n",
      "[tls @ 0x55b3c002a140] IO error: End of file\n",
      "[tls @ 0x55b3bfab85c0] IO error: End of file\n",
      "[tls @ 0x7fac847f9940] IO error: Connection reset by peer\n",
      "[tls @ 0x7fac847f9940] IO error: Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m frame\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(frame,(\u001b[38;5;241m1020\u001b[39m,\u001b[38;5;241m600\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m bbox,label,conf\u001b[38;5;241m=\u001b[39m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_common_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m frame\u001b[38;5;241m=\u001b[39mdraw_bbox(frame,bbox,label,conf)\n\u001b[1;32m     12\u001b[0m c\u001b[38;5;241m=\u001b[39mlabel\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/cvlib/object_detection.py:135\u001b[0m, in \u001b[0;36mdetect_common_objects\u001b[0;34m(image, confidence, nms_thresh, model, enable_gpu)\u001b[0m\n\u001b[1;32m    131\u001b[0m     net\u001b[38;5;241m.\u001b[39msetPreferableTarget(cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mDNN_TARGET_CUDA)\n\u001b[1;32m    133\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[0;32m--> 135\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_output_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m class_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    138\u001b[0m confidences \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stream = CamGear(source='https://www.youtube.com/watch?v=DjdUEyjx8GM', stream_mode = True, logging=True).start() # YouTube Video URL as input\n",
    "count=0\n",
    "while True:\n",
    "    frame = stream.read()\n",
    "    count += 1\n",
    "    if count % 6 != 0:\n",
    "        continue\n",
    " \n",
    "    frame=cv2.resize(frame,(1020,600))\n",
    "    bbox,label,conf=cv.detect_common_objects(frame)\n",
    "    frame=draw_bbox(frame,bbox,label,conf)\n",
    "    c=label.count('person')\n",
    "    cv2.putText(frame,str(c),(50,60),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),3)\n",
    "    cv2.imshow(\"FRAME\",frame)\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420c0ce-7f7c-4cf3-ab6a-7614a7662946",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841b532-def4-4da9-9afd-dd87877b601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vidgear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d2240-451d-4e12-a54d-9089d0b4413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb47fa-9731-4cce-affa-9ba213c71f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install websockets<12.0>=10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48719c07-412d-4cbc-9dff-f4ca2ddf9496",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1269737412.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    stream.release() cv2.destroyAllWindows()\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stream = CamGear(source='https://www.youtube.com/watch?v=DjdUEyjx8GM', stream_mode = True, logging=True).start() # YouTube Video URL as input count=0 while True: frame = stream.read() count += 1 if count % 6 != 0: continue\n",
    "\n",
    "frame=cv2.resize(frame,(1020,600))\n",
    "bbox,label,conf=cv.detect_common_objects(frame)\n",
    "frame=draw_bbox(frame,bbox,label,conf)\n",
    "c=label.count('person')\n",
    "cv2.putText(frame,str(c),(50,60),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),3)\n",
    "cv2.imshow(\"FRAME\",frame)\n",
    "if cv2.waitKey(1)&0xFF==27:\n",
    "    \n",
    "    break\n",
    "\n",
    "stream.release() cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea12c5-02ff-4833-91c6-67ae9b40ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc961e-490b-4d1f-a94c-18e6b3a164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "git remote add origin https://github.com/YASH-YADAV-dynamo/People.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bc4a7e-1cbd-4d7f-a2ce-fc5a29e3ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m08:42:07\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;31m\u001b[2;33mWARNING \u001b[0m :: \u001b[1;37mGStreamer not found!\u001b[0m\n",
      "\u001b[32m08:42:07\u001b[0m :: \u001b[1;35m   Helper    \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mSelecting `best` resolution for streams.\u001b[0m\n",
      "\u001b[32m08:42:07\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37mVerifying Streaming URL using yt-dlp backend. Please wait...\u001b[0m\n",
      "\u001b[32m08:42:15\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;36m  INFO  \u001b[0m :: \u001b[1;37m[Backend] :: Streaming URL is fully supported. Available Streams are: [144p, 240p, 360p, 480p, 720p, 1080p, best, worst]\u001b[0m\n",
      "\u001b[32m08:42:15\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;31m\u001b[2;33mWARNING \u001b[0m :: \u001b[1;37mLivestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\u001b[0m\n",
      "\u001b[32m08:42:15\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mUsing `best` resolution for streaming.\u001b[0m\n",
      "\u001b[32m08:42:15\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mYouTube source ID: `DjdUEyjx8GM`, Title: `【 LIVE 】東京都 新宿 歌舞伎町 24時間 ライブ / Tokyo Shinjuku Kabukicho Live 2024-04-09 08:42`, Quality: `best`\u001b[0m\n",
      "\u001b[32m08:42:15\u001b[0m :: \u001b[1;35m   CamGear   \u001b[0m :: \u001b[1;33m DEBUG  \u001b[0m :: \u001b[1;37mEnabling Threaded Queue Mode for the current video source!\u001b[0m\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "[tls @ 0x557469f77a80] IO error: End of file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m1020\u001b[39m, \u001b[38;5;241m600\u001b[39m))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Detect objects\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m bbox, label, conf \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_common_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes and count people\u001b[39;00m\n\u001b[1;32m     33\u001b[0m frame \u001b[38;5;241m=\u001b[39m draw_bbox(frame, bbox, label, conf)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/cvlib/object_detection.py:135\u001b[0m, in \u001b[0;36mdetect_common_objects\u001b[0;34m(image, confidence, nms_thresh, model, enable_gpu)\u001b[0m\n\u001b[1;32m    131\u001b[0m     net\u001b[38;5;241m.\u001b[39msetPreferableTarget(cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mDNN_TARGET_CUDA)\n\u001b[1;32m    133\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[0;32m--> 135\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_output_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m class_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    138\u001b[0m confidences \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from vidgear.gears import CamGear\n",
    "import csv\n",
    "import datetime\n",
    "from cvlib.object_detection import draw_bbox\n",
    "# Initialize CSV file\n",
    "csv_file = open('people_count.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Timestamp', 'People Count'])\n",
    "\n",
    "# Initialize video stream\n",
    "stream = CamGear(source='https://www.youtube.com/watch?v=DjdUEyjx8GM', stream_mode=True, logging=True).start()\n",
    "detector = cv\n",
    "\n",
    "# Initialize variables\n",
    "prev_count = 0\n",
    "count=0\n",
    "while True:\n",
    "    frame = stream.read()\n",
    "\n",
    "    # Process frame every 6th iteration\n",
    "    count += 1\n",
    "    if count % 6 != 0:\n",
    "        continue\n",
    "    \n",
    "    # Resize frame\n",
    "    frame = cv2.resize(frame, (1020, 600))\n",
    "\n",
    "    # Detect objects\n",
    "    bbox, label, conf = detector.detect_common_objects(frame)\n",
    "    \n",
    "    # Draw bounding boxes and count people\n",
    "    frame = draw_bbox(frame, bbox, label, conf)\n",
    "    current_count = label.count('person')\n",
    "    cv2.putText(frame, str(current_count), (50, 60), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)\n",
    "    \n",
    "    # Check for changes in count\n",
    "    if current_count != prev_count:\n",
    "        # Write data to CSV\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        csv_writer.writerow([timestamp, current_count])\n",
    "        prev_count = current_count\n",
    "    \n",
    "    # Display frame\n",
    "    cv2.imshow(\"FRAME\", frame)\n",
    "    \n",
    "    # Exit loop on ESC key press\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "stream.stop()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5836199-b3f5-46c4-9b75-c5591794b19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2830201818.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    git init\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af82e189-0a54-4227-849b-49db7a7120e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1692283080.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    git branch -M main\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f270229-5390-4428-a54e-3e5f4398ed17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
